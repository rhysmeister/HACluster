---
  - hosts: all
    gather_facts: yes
    become: yes
    vars:
      host_list: ""
      clustering_packages:
        - corosync
        - pacemaker
        - pcs
        - crmsh
      cluster_name: hacluster
      floating_ip: 192.168.44.99
      additional_packages:
        - wget
      fencing_agents:
        - fence-virt
        - fence-virtd
        - fence-virtd-libvirt
        - fence-virtd-multicast
        - fence-virtd-serial

    tasks:

    - name: Ensure additional packages are installed
      yum:
        name: "{{ additional_packages }}"
        state: installed

    - name: Ensure fencing agents are installed
      yum:
        name: "{{ fencing_agents }}"
        state: present

    - name: Ensure cluster directory exists
      file:
        path: /etc/cluster
        state: directory

    - name: Create a unique fence key for each node
      shell: "dd if=/dev/urandom of=files/fence_xvm.key bs=4k count=1"
      args:
        creates: "/etc/cluster/fence_xvm.key"
      run_once: yes
      become: no
      delegate_to: localhost

    - name: Copy all node files to each host
      copy:
        src: "{{ item }}"
        dest: /etc/cluster
      with_fileglob: files/fence_xvm.key

    - name: Ensure the fencing config file exists
      template:
        src: templates/fence_virt.conf.j2
        dest: /etc/fence_virt.conf

    - name: Ensure the fence_virtd service is started
      service:
        name: fence_virtd
        state: started
        enabled: yes

    - name: Ensure crmsh repo has been setup
      script: files/crmsh_repo.sh
      args:
        creates: /etc/yum.repo.d/network:ha-clustering:Stable.repo

    - name: Ensure /etc/hosts is setup
      template:
        src: hosts.j2
        dest: /etc/hosts

    - name: Update ca certs
      yum:
        name: ca-certificates
        state: latest

    - name: Ensure epel is available
      yum:
        name: epel-release
        state: present

    - name: Install nginx webserver
      yum:
        name: nginx
        state: present

    - name: Ensure firewall rules exist
      firewalld:
        service: "{{ item }}"
        permanent: yes
        state: enabled
        immediate: yes
      with_items:
        - http
        - https
        - high-availability

    - name: Ensure port for multicast fencing is open
      firewalld:
        port: "{{ item }}"
        permanent: yes
        state: enabled
        immediate: yes
      with_items:
        - 1229/tcp
        - 1229/udp

    - name: Ensure clustering software is installed
      yum:
        name: "{{ clustering_packages }}"
        state: present

    - name: Ensure clustering services are enabled at boot
      service:
        name: "{{ item }}"
        enabled: yes
      with_items:
        - pcsd
        - corosync
        - pacemaker

    - name: Ensure pcsd is started
      service:
        name: pcsd
        state: started

    - name: Ensure the password for the hacluster user is syncronised
      user:
        name: hacluster
        password: "{{ 'SecretPasswordReallyShouldbeinVault' | password_hash('sha512', 'mysecretsalt') }}"

    - name: Setup list of cluster hosts
      set_fact:
        host_list: "{{ host_list }}{{ (play_hosts.index(item) == 0) | ternary('',' ') }}{{ item }}"
      loop: "{{ play_hosts }}"
      run_once: yes

    - debug:
        var: host_list
      run_once: yes

    - name: Setup the cluster authentication (Should only need to run on one host)
      shell: pcs cluster auth {{ host_list }} -u hacluster -p SecretPasswordReallyShouldbeinVault --force && touch cluster_auth.success
      args:
        creates: cluster_auth.success
      when: ansible_hostname == "cnode1"

    - name: Setup the cluster (Should only need to run on one host)
      shell: pcs cluster setup --name {{ cluster_name }} {{ host_list }} && touch cluster.success
      args:
        creates: cluster.success
      when: ansible_hostname == "cnode1"

    - name: Enable all cluster services (Should only need to run on one host)
      shell: pcs cluster enable --all && touch cluster_enabled.success
      args:
        creates: cluster_enabled.success
      when: ansible_hostname == "cnode1"

    - name: Ensure the cluster services have started the first time (Should only need to run on one host)
      shell: pcs cluster start --all && touch cluster_services.success
      args:
        creates: cluster_services.success
      when: ansible_hostname == "cnode1"

    - name: Add a floating ip (Should only need to run on one host)
      shell: pcs resource create floating_ip ocf:heartbeat:IPaddr2 ip={{ floating_ip }} cidr_netmask=32 op monitor interval=60s && touch floating_ip.success
      args:
        creates: floating_ip.success
      when: ansible_hostname == "cnode1"

    - name: Add http server resource (Should only need to run on one host)
      shell: pcs resource create http_server ocf:heartbeat:nginx configfile="/etc/nginx/nginx.conf" op monitor timeout="20s" interval="60s" && touch http.success
      args:
        creates: http.success
      when: ansible_hostname == "cnode1"

    - name: Ensure colocation constraint is added
      shell: pcs constraint colocation add http_server floating_ip INFINITY && touch colocation.success
      args:
        creates: colocation.success
      when: ansible_hostname == "cnode1"

    - name: Ensure order constraint is added
      shell: pcs constraint order floating_ip then http_server && touch order.success
      args:
        creates: order.success
      register: order_constraint
      when: ansible_hostname == "cnode1"

    - name: Restart the cluster if required
      shell: pcs cluster stop --all && pcs cluster start --all
      when: order_constraint.changed == True

    - name: Ensure page for each node exists
      copy:
        content: This is the default page for {{ ansible_hostname }}
        dest: /usr/share/nginx/html/index.html
